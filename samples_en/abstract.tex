\chapter*{Abstract}
\label{ch:abstract}

Financial prediction presents an intriguing task, as numerous factors influence stock prices. Particularly, financial time series data pose a formidable obstacle to prediction due to the intricate modeling required to capture both short-term fluctuations and long-term temporal dependencies within the dataset.
Transformers have remarkable success in many tasks in natural language processing and computer vision using attention mechanisms, which also triggered great interest in the time series community. The ability to capture long-range dependencies and interaction and the ability to learn and understand languages lead to the understanding of the financial market and recognize the historical pattern of prices. While the study of Transformers in stock prediction is not novel, existing research predominantly relies on historical prices of individual features for singular predictions, thus limiting the ability to comprehensively recognize or understand broader market trends.
In this paper, we present the study into the different markets by selecting correlation features to enhance the accuracy in predicting multiple stock prices and minimizing the error associated with exceptional cases in stock market analysis. Combining Transformer model with Time2Vec technique as Encoder. We conducted a comparative analysis of our results with others models and suggested potential directions for advancing our research.
